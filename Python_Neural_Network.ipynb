{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook focuses on classifying handwritten digits with the MNIST data set.\n",
    "\n",
    "Here, models were created for binary classification. Specifically, data of 0 and 6 were used due to the two digits being relatively similar to each other.\n",
    "\n",
    "Some elements are based on Ng (2017), with modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads packages\n",
    "\n",
    "import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data sets\n",
    "\n",
    "dat_train_labels=mnist.train_labels()\n",
    "dat_train_images=mnist.train_images()\n",
    "\n",
    "dat_test_labels=mnist.test_labels()\n",
    "dat_test_images=mnist.test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates data sets for binary classification (i.e. only 0 and 6)\n",
    "\n",
    "dat_train_binary_labels=dat_train_labels[np.logical_or(dat_train_labels==0, dat_train_labels==6)]\n",
    "dat_train_binary_images=dat_train_images[np.logical_or(dat_train_labels==0, dat_train_labels==6)]\n",
    "\n",
    "dat_test_binary_labels=dat_test_labels[np.logical_or(dat_test_labels==0, dat_test_labels==6)]\n",
    "dat_test_binary_images=dat_test_images[np.logical_or(dat_test_labels==0, dat_test_labels==6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The train set contains 11841 images, 5923 images are 0 and 5918 are 6.\n",
    "\n",
    "The test set contains 1938 images, 980 images are 0 and 958 are 6.\n",
    "\n",
    "Each image has 28 $\\times$ 28 pixels, each of which is associated with a grayscale value (0 is completely black, 255 is completely white).\n",
    "\n",
    "Below are two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8856f49c40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dat_train_binary_images[0], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8856695100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dat_train_binary_images[2], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "\n",
    "Data sets containing the images were in a three-dimensional format (samples $\\times$ rows of pixels $\\times$ columns of pixels), and therefore were reshaped into a two-dimensional (total pixels $\\times$ samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_reshape(data):\n",
    "    \n",
    "    data_reshaped=data.reshape((data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    data_reshaped=data_reshaped.T\n",
    "    \n",
    "    return data_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train_binary_images=func_reshape(dat_train_binary_images)\n",
    "dat_test_binary_images=func_reshape(dat_test_binary_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 11841)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_train_binary_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1938)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_test_binary_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation\n",
    "\n",
    "The pixel data were further standardised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train_binary_images=dat_train_binary_images/255\n",
    "dat_test_binary_images=dat_test_binary_images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recoding\n",
    "\n",
    "One final step in data preparation was to make the labels into 0 and 1.\n",
    "\n",
    "For the sake of convenience, all 6 were recoded as 1. In other words, the task became whether a handwritten digit was 6 as opposed to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train_binary_labels[dat_train_binary_labels==6]=1\n",
    "dat_test_binary_labels[dat_test_binary_labels==6]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11841,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_train_binary_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_test_binary_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Logistic Regression)\n",
    "\n",
    "A logistic regression can be viewed as the simplest neural network possible for a binary classification, that is, a one-layer neural network.\n",
    "\n",
    "The input layer has $\\mathbf{X}$ which is a matrix of input greyscale values (total pixels $\\times$ samples).\n",
    "\n",
    "The output layer has $\\mathbf{W}$ which is a vector of weights (total pixels $\\times$ 1), $b$ which is a scalar bias term, and $\\mathbf{A}$ which is a vector of predicted label (1 $\\times$ samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A} = \\sigma(\\mathbf{W}^\\intercal \\mathbf{X} + b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma$ is the sigmoid function which is the inverse of the logit function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $m$ sample, the cost function $J$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J =\n",
    "-\\frac{1}{m} \\sum^m_{i=1} [y^{(i)} \\log(a^{(i)}) + (1 - y^{(i)}) \\log(1 - a^{(i)})]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $i$ is the sample index.\n",
    "\n",
    "Cost function $J$ is the normalised model errors across all samples.\n",
    "\n",
    "The unnormalised cost function, $mJ$,  is known as deviance ($\\chi^2$) in traditional statistics. $-mJ$ is simply the log likelihood of $m$ independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    \n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_forward_prop_model_1(Y, X, W, b, m):\n",
    "    \n",
    "    A=sigma(W.T @ X + b)\n",
    "    \n",
    "    J= (-1/m) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A))\n",
    "    \n",
    "    return A, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent of the parameters is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}} =\n",
    "\\frac{1}{m} \\mathbf{X} (\\mathbf{A} - \\mathbf{Y})^\\intercal\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial b} =\n",
    "\\frac{1}{m} \\sum^m_{i=1} (a^{(i)} - y^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two parameters are updated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{W} =\n",
    "\\mathbf{W} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b = b - \\alpha \\frac{\\partial J}{\\partial b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_back_prop_model_1(Y, X, W, b, m, A, alpha):\n",
    "    \n",
    "    dW=(X @ (A-Y).T)/m\n",
    "    \n",
    "    db=(np.sum(A-Y))/m\n",
    "    \n",
    "    W_new=W-alpha*dW\n",
    "    \n",
    "    b_new=b-alpha*db\n",
    "    \n",
    "    return W_new, b_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, $\\mathbf{W}$ and $b$ were initialised. $\\mathbf{W}$ is a vector of 0 while $b$ is just 0.\n",
    "\n",
    "Second, $\\alpha$ was set to 0.01.\n",
    "\n",
    "Then the model was run for 100 iterations, in each of which predictions were made for both the train and test sets using the current $\\mathbf{W}$ and $b$ values, and prediction accuracy was calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_forward_back_prop_model_1(Y, X, W, b, alpha):\n",
    "    \n",
    "    m=Y.shape[0] # number of samples\n",
    "    \n",
    "    A, J=func_forward_prop_model_1(Y, X, W, b, m)\n",
    "    \n",
    "    W_new, b_new=func_back_prop_model_1(Y, X, W, b, m, A, alpha)\n",
    "    \n",
    "    return J, W_new, b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_prediction_model_1(Y, X, W_new, b_new):\n",
    "    \n",
    "    A_predict=sigma(W_new.T @ X + b_new)  \n",
    "    A_predict=np.where(A_predict < .5, 0, 1)\n",
    "    \n",
    "    accuracy=Y.shape[0]-np.sum(np.abs(A_predict - Y)) # total - wrong predictions\n",
    "    accuracy=accuracy/Y.shape[0] # normalised\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=.01\n",
    "\n",
    "chain_W=[np.zeros((dat_train_binary_images.shape[0], 1))] # each W is the weights in an iteration\n",
    "chain_b=[0] # each b is the bias in an iteration\n",
    "\n",
    "chain_J=[]\n",
    "\n",
    "chain_accuracy_train=[]\n",
    "chain_accuracy_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    J, W_new, b_new=func_forward_back_prop_model_1(dat_train_binary_labels, dat_train_binary_images, chain_W[i], chain_b[i], alpha)\n",
    "    \n",
    "    chain_J.append(J)\n",
    "    chain_W.append(W_new)\n",
    "    chain_b.append(b_new)\n",
    "    \n",
    "    accuracy_train=func_prediction_model_1(dat_train_binary_labels, dat_train_binary_images, W_new, b_new)\n",
    "    chain_accuracy_train.append(accuracy_train)\n",
    "    \n",
    "    accuracy_test=func_prediction_model_1(dat_test_binary_labels, dat_test_binary_images, W_new, b_new)\n",
    "    chain_accuracy_test.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The results suggested that the task is probably too simple.\n",
    "\n",
    "The train set was able to achieve a 91% accuracy right at the beginning and 97% after 100 iterations. While an accuracy close to 100% is not uncommon in training a neural network, the test set was also able to achieve a 97% accuracy with this one-layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9148720547251077,\n",
       " 0.9224727641246516,\n",
       " 0.927033189764378,\n",
       " 0.9317625200574275,\n",
       " 0.9369141119837852]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_train[0:5] # train set, 5 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.969850519381809,\n",
       " 0.969850519381809,\n",
       " 0.969850519381809,\n",
       " 0.9700194240351322,\n",
       " 0.9701883286884554]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_train[94:99] # train set, 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8978328173374613,\n",
       " 0.9066047471620227,\n",
       " 0.9143446852425181,\n",
       " 0.9231166150670794,\n",
       " 0.9277605779153767]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_test[0:5] # test set, 5 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9700722394220846,\n",
       " 0.9705882352941176,\n",
       " 0.9705882352941176,\n",
       " 0.9705882352941176,\n",
       " 0.9705882352941176]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_test[94:99] # test set, 100 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 (L-layer Neural Network)\n",
    "\n",
    "The input layer ($l=0$) has $\\mathbf{X}$ which is a matrix of input greyscale values (number of units in layer 0 $\\times$ samples).\n",
    "\n",
    "Each layer $l$ has $\\mathbf{W}^{[l]}$ which is a matrix of weights (number of units in layer $l$ $\\times$ numer of units in layer $l-1$), $\\mathbf{b}^{[l]}$ which is a vector of bias terms (number of units in layer $l$ $\\times$ 1), and $\\mathbf{A}^{[l]}$ which is a matrix of output (numer of units in layer $l$ $\\times$ samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "\n",
    "The activation of layer $l$ is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A}^{[l]} =\n",
    "g^{[l]}(\\mathbf{W}^{[l]} \\mathbf{A}^{[l-1]} + \\mathbf{b}^{[l]})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $g^{[l]}$ is the activation function of layer $l$.\n",
    "\n",
    "$\\mathbf{A}^{[0]}$ is the input $\\mathbf{X}$. For the final layer $l=L$, $\\mathbf{A}^{[L]}$ is the predicted value $\\hat{\\mathbf{Y}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions\n",
    "\n",
    "For all layers besides the last one, $l \\neq L$, Rectified Linear Units (ReLU) was used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(z) =\n",
    "\\text{max}(0, z) = \\begin{cases}\n",
    "z, z>0 \\\\\n",
    "0, z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final layer $l=L$, the sigmoid function was used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_forward_prop_model_2(n_layers, X, W, b):\n",
    "    \n",
    "    A=[]\n",
    "    \n",
    "    A.append(relu(W[0] @ X + b[0])) # first layer\n",
    "    \n",
    "    if (n_layers>2): # if there are more than two layers, all layers between 1 and L-1\n",
    "    \n",
    "        for l in range(1, n_layers-1): # remember the indices is exclusive of the last digit\n",
    "    \n",
    "            A.append(relu(W[l] @ A[l-1] + b[l]))\n",
    "        \n",
    "    A.append(sigma(W[n_layers-1] @ A[n_layers-2] + b[n_layers-1])) # the final layer L\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation\n",
    "\n",
    "Back propagation initiated with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d \\mathbf{A}^{[L]} = (-\\frac{y^{(1)}}{a^{(1)}} + \\frac{(1-y^{(1)})}{(1-a^{(1)})} ... -\\frac{y^{(m)}}{a^{(m)}} + \\frac{(1-y^{(m)})}{(1-a^{(m)})})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $d \\mathbf{A}^{[L]}$, the gradient descent of the two parameters in each layer could be calculated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d \\mathbf{Z}^{[l]} = \n",
    "d \\mathbf{A}^{[l]} \\circ g^{[l]'}(\\mathbf{W}^{[l]} \\mathbf{A}^{[l-1]} + \\mathbf{b}^{[l]})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d \\mathbf{W}^{[l]} =\n",
    "\\frac{1}{m} d \\mathbf{Z}^{[l]} \\cdot \\mathbf{A}^{[l-1] \\intercal}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d \\mathbf{b}^{[l]} =\n",
    "\\frac{1}{m} \\sum^m_{i=1} d \\mathbf{Z}^{[l](i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d \\mathbf{A}^{[l-1]} =\n",
    "\\mathbf{W}^{[l] \\intercal} d \\mathbf{Z}^{[l]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the two parameters in each layer were updated using the same formula as above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta^{[l]} := \\theta^{[l]} - \\alpha d \\theta^{[l]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(z):\n",
    "    \n",
    "    return np.where(z>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_derivative(z):\n",
    "    \n",
    "    return (sigma(z) * (1-sigma(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_back_prop_model_2(n_layers, Y, X, A, W, b, alpha):\n",
    "    \n",
    "    dA=[]\n",
    "    dZ=[]\n",
    "    dW=[]\n",
    "    db=[]\n",
    "    \n",
    "    m=Y.shape[0] # number of samples\n",
    "    \n",
    "    for l in range(n_layers):\n",
    "        \n",
    "        dA.append([])\n",
    "        dZ.append([])\n",
    "        dW.append([])\n",
    "        db.append([])\n",
    "        \n",
    "    # the final layer L\n",
    "        \n",
    "    dA[n_layers-1]= -(np.divide(Y, A[n_layers-1]) - np.divide(1-Y, 1-A[n_layers-1]))\n",
    "    \n",
    "    dZ[n_layers-1]=dA[n_layers-1] * sigma_derivative(W[n_layers-1] @ A[n_layers-2] + b[n_layers-1])\n",
    "    \n",
    "    dW[n_layers-1]=(dZ[n_layers-1] @ A[n_layers-2].T)/m\n",
    "    \n",
    "    db[n_layers-1]=np.sum(dZ[n_layers-1], axis=1, keepdims=True)/m\n",
    "    \n",
    "    for l in range(n_layers-2, 0, -1):\n",
    "        \n",
    "        dA[l]=W[l+1].T @ dZ[l+1]\n",
    "        \n",
    "        dZ[l]=dA[l] * relu_derivative(W[l] @ A[l-1] + b[l])\n",
    "        \n",
    "        dW[l]=(dZ[l] @ A[l-1].T)/m\n",
    "        \n",
    "        db[l]=np.sum(dZ[l], axis=1, keepdims=True)/m\n",
    "    \n",
    "    # the first layer\n",
    "    \n",
    "    dA[0]=W[1].T @ dZ[1]\n",
    "        \n",
    "    dZ[0]=dA[0] * relu_derivative(W[0] @ X + b[0])\n",
    "        \n",
    "    dW[0]=(dZ[0] @ X.T)/m\n",
    "        \n",
    "    db[0]=np.sum(dZ[0], axis=1, keepdims=True)/m\n",
    "    \n",
    "    for l in range(n_layers):\n",
    "        \n",
    "        W[l]=W[l]-alpha * dW[l]\n",
    "        \n",
    "        b[l]=b[l]-alpha * db[l]\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Models\n",
    "\n",
    "The learning rate $\\alpha$ was set to 0.01 since this value worked well in the previous logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_initalisation_model_2(layer_dimensions):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_layers=len(layer_dimensions)-1 # excludes the input layer\n",
    "\n",
    "    chain_W=[[]] # each W is the weights for all layers in an iteration\n",
    "    chain_b=[[]] # each b is the biases for all layers in an iteration\n",
    "\n",
    "    for l in range(n_layers-1): # layers 1 to L-1\n",
    "    \n",
    "        chain_W[0].append(np.random.randn(layer_dimensions[l+1], layer_dimensions[l])*0.01)\n",
    "        chain_b[0].append(np.zeros((layer_dimensions[l+1], 1)))\n",
    "    \n",
    "    # the following is the final layer L\n",
    "\n",
    "    chain_W[0].append(np.random.randn(1, layer_dimensions[n_layers-1])*0.01)\n",
    "    chain_b[0].append(0)\n",
    "    \n",
    "    return n_layers, chain_W, chain_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_forward_back_prop_model_2(n_layers, Y, X, W, b, alpha):\n",
    "    \n",
    "    A=func_forward_prop_model_2(n_layers, X, W, b)\n",
    "    \n",
    "    W_new, b_new=func_back_prop_model_2(n_layers, Y, X, A, W, b, alpha)\n",
    "    \n",
    "    return W_new, b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_prediction_model_2(n_layers, Y, X, W_new, b_new):\n",
    "    \n",
    "    A=[]\n",
    "    \n",
    "    A.append(relu(W_new[0] @ X + b_new[0])) # first layer\n",
    "    \n",
    "    if (n_layers>2): # if there are more than two layers, all layers between 1 and L-1\n",
    "    \n",
    "        for l in range(1, n_layers-1): # remember the indices is exclusive of the last digit\n",
    "    \n",
    "            A.append(relu(W_new[l] @ A[l-1] + b_new[l]))\n",
    "        \n",
    "    A.append(sigma(W_new[n_layers-1] @ A[n_layers-2] + b_new[n_layers-1])) # the final layer L\n",
    "    \n",
    "    A_predict=A[n_layers-1]\n",
    "    A_predict=np.where(A_predict < .5, 0, 1)\n",
    "    \n",
    "    accuracy=Y.shape[0]-np.sum(np.abs(A_predict - Y)) # total - wrong predictions\n",
    "    accuracy=accuracy/Y.shape[0] # normalised\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer 10-unit Shallow Network\n",
    "\n",
    "Results showed that this model performed worse than the logistic regression model after 100 iterations.\n",
    "\n",
    "Increasing the number of iterations could improve performance, but it was still at below 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_v1, chain_W_v1, chain_b_v1=func_initalisation_model_2([dat_train_binary_images.shape[0], 10, 1]) # includes the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_running_model_2(iterations, n_layers, Y_train, X_train, Y_test, X_test, chain_W, chain_b, alpha):\n",
    "    \n",
    "    chain_accuracy_train=[]\n",
    "    chain_accuracy_test=[]\n",
    "\n",
    "    for i in range(iterations):\n",
    "    \n",
    "        W_new, b_new=func_forward_back_prop_model_2(n_layers, Y_train, X_train, chain_W[i], chain_b[i], alpha)\n",
    "    \n",
    "        chain_W.append(W_new)\n",
    "        chain_b.append(b_new)\n",
    "    \n",
    "        accuracy_train=func_prediction_model_2(n_layers, Y_train, X_train, W_new, b_new)\n",
    "        chain_accuracy_train.append(accuracy_train)\n",
    "    \n",
    "        accuracy_test=func_prediction_model_2(n_layers, Y_test, X_test, W_new, b_new)\n",
    "        chain_accuracy_test.append(accuracy_test)\n",
    "        \n",
    "    return chain_accuracy_train, chain_accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_accuracy_train_v1, chain_accuracy_test_v1=func_running_model_2(100, n_layers_v1, dat_train_binary_labels, dat_train_binary_images, dat_test_binary_labels, dat_test_binary_images, chain_W_v1, chain_b_v1, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7894603496326323,\n",
       " 0.7908960391858796,\n",
       " 0.7925006333924499,\n",
       " 0.793767418292374,\n",
       " 0.7944430369056668]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_train_v1[94:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7502579979360166,\n",
       " 0.7497420020639834,\n",
       " 0.7512899896800825,\n",
       " 0.7523219814241486,\n",
       " 0.7543859649122807]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_test_v1[94:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-layer 10-unit Shallow Network\n",
    "\n",
    "Results showed that increasing the number of layers but not the number of hidden units actually reduced performance. The accuracy of this model was identical to blind guesses.\n",
    "\n",
    "Note that increasing the number of iterations did *not* improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_v2, chain_W_v2, chain_b_v2=func_initalisation_model_2([dat_train_binary_images.shape[0], 10, 10, 10, 10, 1]) # includes the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_accuracy_train_v2, chain_accuracy_test_v2=func_running_model_2(100, n_layers_v2, dat_train_binary_labels, dat_train_binary_images, dat_test_binary_labels, dat_test_binary_images, chain_W_v2, chain_b_v2, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.500211130816654,\n",
       " 0.500211130816654,\n",
       " 0.500211130816654,\n",
       " 0.500211130816654,\n",
       " 0.500211130816654]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_train_v2[94:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5056759545923633,\n",
       " 0.5056759545923633,\n",
       " 0.5056759545923633,\n",
       " 0.5056759545923633,\n",
       " 0.5056759545923633]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_test_v2[94:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer 700-unit Deep Network\n",
    "\n",
    "Results were acceptable at 95% accuracy after 100 iterations and 96% after 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_v3, chain_W_v3, chain_b_v3=func_initalisation_model_2([dat_train_binary_images.shape[0], 700, 1]) # includes the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took a while to run, so the results were saved on disk instead\n",
    "\n",
    "# chain_accuracy_train_v3, chain_accuracy_test_v3=func_running_model_2(200, n_layers_v3, dat_train_binary_labels, dat_train_binary_images, dat_test_binary_labels, dat_test_binary_images, chain_W_v3, chain_b_v3, alpha)\n",
    "\n",
    "# file_NN_2_layers_700_units=open(\"Data/Objects_Neural_Network_Accuracies_2_Layers_700_Units.obj\", \"wb\") \n",
    "# pickle.dump([chain_accuracy_train_v3, chain_accuracy_test_v3], file_NN_2_layers_700_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_NN_2_layers_700_units=open(\"Data/Objects_Neural_Network_Accuracies_2_Layers_700_Units.obj\", \"rb\")\n",
    "chain_accuracy_v3=pickle.load(file_NN_2_layers_700_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9524533400895194,\n",
       " 0.9527911493961658,\n",
       " 0.9532134110294739,\n",
       " 0.9534667680094586,\n",
       " 0.9536356726627818]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v3[0][94:99] # train set, 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9668102356219914,\n",
       " 0.966894687948653,\n",
       " 0.9669791402753146,\n",
       " 0.9669791402753146,\n",
       " 0.9669791402753146]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v3[0][194:199] # train set, 200 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9659442724458205,\n",
       " 0.9659442724458205,\n",
       " 0.9664602683178535,\n",
       " 0.9664602683178535,\n",
       " 0.9664602683178535]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v3[1][194:199] # test set, 200 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer 5000-unit Deep Network\n",
    "\n",
    "Accuracy reached 96% after 100 iterations and marginally increased to 97% after 200 iterations, the latter of which was slightly above that of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_v4, chain_W_v4, chain_b_v4=func_initalisation_model_2([dat_train_binary_images.shape[0], 5000, 1]) # includes the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took a while to run, so the results were saved on disk instead\n",
    "\n",
    "# chain_accuracy_train_v4, chain_accuracy_test_v4=func_running_model_2(200, n_layers_v4, dat_train_binary_labels, dat_train_binary_images, dat_test_binary_labels, dat_test_binary_images, chain_W_v4, chain_b_v4, alpha)\n",
    "\n",
    "# file_NN_2_layers_5000_units=open(\"Data/Objects_Neural_Network_Accuracies_2_Layers_5000_Units.obj\", \"wb\") \n",
    "# pickle.dump([chain_accuracy_train_v4, chain_accuracy_test_v4], file_NN_2_layers_5000_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_NN_2_layers_5000_units=open(\"Data/Objects_Neural_Network_Accuracies_2_Layers_5000_Units.obj\", \"rb\")\n",
    "chain_accuracy_v4=pickle.load(file_NN_2_layers_5000_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9668102356219914,\n",
       " 0.9668102356219914,\n",
       " 0.9670635926019762,\n",
       " 0.9672324972552994,\n",
       " 0.967316949581961]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v4[0][94:99] # train set, 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9733130647749345,\n",
       " 0.9733975171015962,\n",
       " 0.9733975171015962,\n",
       " 0.9733975171015962,\n",
       " 0.9733975171015962]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v4[0][194:199] # train set, 200 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9757481940144479,\n",
       " 0.9757481940144479,\n",
       " 0.9757481940144479,\n",
       " 0.9757481940144479,\n",
       " 0.9757481940144479]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v4[1][194:199] # test set, 200 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-layer 700-unit Deep Network\n",
    "\n",
    "This model required much more iterations to train.\n",
    "\n",
    "The accuracy was at only 62% after 100 iterations, and reached 93% after 500 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_v5, chain_W_v5, chain_b_v5=func_initalisation_model_2([dat_train_binary_images.shape[0], 700, 700, 700, 1]) # includes the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took a while to run, so the results were saved on disk instead\n",
    "\n",
    "# chain_accuracy_train_v5, chain_accuracy_test_v5=func_running_model_2(500, n_layers_v5, dat_train_binary_labels, dat_train_binary_images, dat_test_binary_labels, dat_test_binary_images, chain_W_v5, chain_b_v5, alpha)\n",
    "\n",
    "# file_NN_4_layers_700_units=open(\"Data/Objects_Neural_Network_Accuracies_4_Layers_700_Units.obj\", \"wb\") \n",
    "# pickle.dump([chain_accuracy_train_v5, chain_accuracy_test_v5], file_NN_4_layers_700_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_NN_4_layers_700_units=open(\"Data/Objects_Neural_Network_Accuracies_4_Layers_700_Units.obj\", \"rb\")\n",
    "chain_accuracy_v5=pickle.load(file_NN_4_layers_700_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6069588717169158,\n",
       " 0.609239084536779,\n",
       " 0.6119415589899502,\n",
       " 0.615150747403091,\n",
       " 0.6180221265095853]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v5[0][94:99] # train set, 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9385187061903555,\n",
       " 0.9386031585170171,\n",
       " 0.9386876108436787,\n",
       " 0.9386876108436787,\n",
       " 0.9387720631703403]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v5[0][494:499] # train set, 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9298245614035088,\n",
       " 0.9303405572755418,\n",
       " 0.9308565531475749,\n",
       " 0.9308565531475749,\n",
       " 0.9308565531475749]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_accuracy_v5[1][494:499] # test set, 500 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As the task is very simple, the best model is actually logistic regression due to its high accuracy and being much less computationally intense than deep networks.\n",
    "\n",
    "Nevertheless, some interesting results were observed for neural networks. Shallow networks are clearly useless even when the number of layers or iterations was increased. For deeper networks, accuracy was improved mainly by increasing the number of hidden units. Increasing the number of layers of a deep network required a much larger number of iterations to train, while its performance was still sub-optimal given five times more iterations. In other words, for this particular task, increasing the number of units is the more appropriate strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
